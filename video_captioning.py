# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mECmHnuQ9xTcpE3_GjKvmj3Nh1UuDGyL
"""

import torch
from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline
import cv2
from pathlib import Path
from PIL import Image

# ✅ Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# 🧠 Load BLIP base model (fast, GPU-friendly)
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
model.to(device)

# 🖼️ Frame extractor (1 frame every 2 seconds)
def extract_key_frames(video_path, sample_rate_sec=2):
    cap = cv2.VideoCapture(str(video_path))
    fps = cap.get(cv2.CAP_PROP_FPS)
    interval = int(fps * sample_rate_sec)
    frames, frame_id = [], 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if frame_id % interval == 0:
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(Image.fromarray(image))
        frame_id += 1
    cap.release()
    return frames

# 🧾 Generate captions for each frame
def caption_frames(frames):
    captions = []
    for image in frames:
        inputs = processor(images=image, return_tensors="pt").to(device)
        output = model.generate(**inputs, max_new_tokens=50)
        caption = processor.batch_decode(output, skip_special_tokens=True)[0]
        captions.append(caption.strip())
    return captions

# 📃 Summarize the captions
def summarize_captions(captions):
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn", device=0 if torch.cuda.is_available() else -1)
    text = ". ".join(captions)
    summary = summarizer(text, max_length=60, min_length=20, do_sample=False)
    return summary[0]['summary_text']

# 🧪 One-video processor
def process_single_video(video_path_str):
    video_path = Path(video_path_str)
    if not video_path.exists():
        raise FileNotFoundError(f"❌ Video not found: {video_path_str}")

    print(f"📹 Processing: {video_path.name}")
    frames = extract_key_frames(video_path)
    if not frames:
        print("⚠️ No frames extracted — is the video too short?")
        return ""

    captions = caption_frames(frames)
    summary = summarize_captions(captions)

    print(f"\n✅ Caption summary for {video_path.name}:\n➡️ {summary}\n")
    return summary


# Example: your video is in Google Drive > MyDrive > video_captions > test1.mp4
video_path = "/content/#10.avi"
summary = process_single_video(video_path)